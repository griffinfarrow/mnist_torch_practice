{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach to the problem that uses transfer learning on existing ResNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 (for ResNET)\n",
    "    transforms.ToTensor(),  # Converts image to a PyTorch tensor\n",
    "    transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),  # Apply Gaussian blur\n",
    "    transforms.RandomRotation(degrees=30),  # Apply random rotation (range: -30 to +30 degrees)\n",
    "])\n",
    "custom_val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 (for ResNET)\n",
    "    transforms.ToTensor() # Converts image to a PyTorch tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=custom_train_transform\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=custom_val_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Griff_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Griff_CNN, self).__init__()\n",
    "\n",
    "        self.model = models.resnet18(weights='DEFAULT')\n",
    "\n",
    "        # Modify the first convolution layer to accept 1 channel instead of 3\n",
    "        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "        # Replace the last fully connected layer with a new one for 10 classes\n",
    "        self.model.fc = torch.nn.Linear(in_features=self.model.fc.in_features, out_features=10)\n",
    "\n",
    "        # Freeze all layers except the final fully connected layer\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        for param in self.model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x): \n",
    "        \n",
    "        x = self.model(x)\n",
    "\n",
    "        return x\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "model = Griff_CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, history, device):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "\n",
    "    train_loss, correct_guesses = 0., 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # forward prediction\n",
    "        pred = model(X) \n",
    "        loss = loss_fn(pred, y)\n",
    "        correct = (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() \n",
    "        correct_guesses += correct \n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            current = batch * len(X)\n",
    "            print(f\"loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    train_loss /= num_batches \n",
    "    correct_guesses /= size\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_accuracy'].append(correct_guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, history, device):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0., 0. \n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X) \n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches \n",
    "    correct /= size \n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    history['val_loss'].append(test_loss)\n",
    "    history['val_accuracy'].append(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "batchsize = 64 # mini-batch size \n",
    "nworkers = 4\n",
    "lr = 1.0e-3 # learning rate\n",
    "epochs = 1 # number of training epochs \n",
    "\n",
    "# ADAM optimizer parameters\n",
    "beta1 = 0.9 \n",
    "beta2 = 0.999 \n",
    "eps = 1.0e-8\n",
    "lambd = 1.0e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimiser\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=lr, \n",
    "                             betas=(beta1, beta2), \n",
    "                             eps=eps, \n",
    "                             weight_decay=lambd)\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batchsize, num_workers=nworkers)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batchsize, num_workers=nworkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'epoch' : [], \n",
    "           'train_loss' : [],\n",
    "           'train_accuracy' : [],\n",
    "           'val_loss': [],\n",
    "           'val_accuracy' : []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    history['epoch'].append(t+1)\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, history, device)\n",
    "    test_loop(test_dataloader, model, loss_fn, history, device)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(history['epoch'], history['train_loss'], color = 'red', linestyle = '--', label = 'Train')\n",
    "ax.plot(history['epoch'], history['val_loss'], color = 'blue', linestyle = '--', label = \"Test\")\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(history['epoch'], 100*np.array(history['train_accuracy']), color = 'red', linestyle = '-')\n",
    "ax1.plot(history['epoch'], 100*np.array(history['val_accuracy']), color = 'blue', linestyle = '-')\n",
    "\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax1.set_ylabel(\"Accuracy (%)\")\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist_practice_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
