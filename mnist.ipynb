{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classifier  \n",
    "  \n",
    "Using Pytorch and CNNs to build a classifier for the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts image to a PyTorch tensor\n",
    "    transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),  # Apply Gaussian blur\n",
    "    transforms.RandomRotation(degrees=30),  # Apply random rotation (range: -30 to +30 degrees)\n",
    "])\n",
    "custom_val_transform = transforms.Compose([\n",
    "    transforms.ToTensor() # Converts image to a PyTorch tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in MNIST dataset\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=custom_train_transform\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=custom_val_transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "label =  [5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Playing around a bit with DataLoaders so we can understand what is going on\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=1, num_workers=1)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1, num_workers=1)\n",
    "\n",
    "for batch, (img, label) in enumerate(train_dataloader):\n",
    "    print(batch)\n",
    "    print(\"label = \", label.numpy())\n",
    "    plt.figure()\n",
    "    plt.imshow(img.squeeze(), cmap='grey')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Griff_CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Griff_CNN, self).__init__()\n",
    "\n",
    "        # First convolutional layer + batch normalization\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1) # should be 16x28x28 after\n",
    "        self.bn1 = nn.BatchNorm2d(16)  # BatchNorm for 16 channels\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # should be 16x14x14 after\n",
    "        \n",
    "        # Second convolutional layer + batch normalization\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=24, kernel_size=3, stride=1, padding=1) # should be 24x14x14 after\n",
    "        self.bn2 = nn.BatchNorm2d(24)  # BatchNorm for 24 channels\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # should be 24x7x7 after\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(in_features=24*7*7, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=256)\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=10)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # First convolution block\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)  # Batch Normalization after convolution\n",
    "        x = F.relu(x)  # Apply ReLU after BatchNorm\n",
    "        x = self.pool1(x)  # Max pooling\n",
    "        \n",
    "        # Second convolution block\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)  # Batch Normalization after convolution\n",
    "        x = F.relu(x)  # Apply ReLU after BatchNorm\n",
    "        x = self.pool2(x)  # Max pooling\n",
    "        \n",
    "        # Flatten the tensor for fully connected layers\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # Final output\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Griff_CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0818, -0.0975, -0.0950,  0.0195,  0.1488,  0.0071, -0.0303,  0.0396,\n",
      "          0.0663, -0.0863]], device='mps:0', grad_fn=<LinearBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# test that results are sensible\n",
    "\n",
    "input_tensor = torch.randn(1, 1, 28, 28).to(device)\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key hyperparameters\n",
    "\n",
    "batchsize = 64 # mini-batch size \n",
    "nworkers = 4\n",
    "lr = 1.0e-3 # learning rate\n",
    "epochs = 10 # number of training epochs \n",
    "# ADAM optimiser parameter\n",
    "beta1 = 0.9 \n",
    "beta2 = 0.999 \n",
    "eps = 1.0e-8\n",
    "lambd = 1.0e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimiser\n",
    "optimiser = torch.optim.Adam(model.parameters(), \n",
    "                             lr=lr, \n",
    "                             betas=(beta1, beta2), \n",
    "                             eps=eps, \n",
    "                             weight_decay=lambd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=batchsize, num_workers=nworkers)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batchsize, num_workers=nworkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, history):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # forward prediction\n",
    "        pred = model(X) \n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batchsize + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    history['test_loss'].append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, history):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0., 0. \n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X) \n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches \n",
    "    correct /= size \n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    history['val_loss'].append(test_loss)\n",
    "    history['accuracy'].append(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'epoch' : [], \n",
    "           'test_loss' : [],\n",
    "           'val_loss': [],\n",
    "           'accuracy' : []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.303391  [   64/60000]\n",
      "loss: 0.133347  [ 6464/60000]\n",
      "loss: 0.131956  [12864/60000]\n",
      "loss: 0.064049  [19264/60000]\n",
      "loss: 0.110302  [25664/60000]\n",
      "loss: 0.126424  [32064/60000]\n",
      "loss: 0.086122  [38464/60000]\n",
      "loss: 0.192132  [44864/60000]\n",
      "loss: 0.140209  [51264/60000]\n",
      "loss: 0.028687  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.057074 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.026929  [   64/60000]\n",
      "loss: 0.083173  [ 6464/60000]\n",
      "loss: 0.065631  [12864/60000]\n",
      "loss: 0.017131  [19264/60000]\n",
      "loss: 0.049385  [25664/60000]\n",
      "loss: 0.024975  [32064/60000]\n",
      "loss: 0.049445  [38464/60000]\n",
      "loss: 0.022071  [44864/60000]\n",
      "loss: 0.085519  [51264/60000]\n",
      "loss: 0.015511  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.043373 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.026244  [   64/60000]\n",
      "loss: 0.087121  [ 6464/60000]\n",
      "loss: 0.045486  [12864/60000]\n",
      "loss: 0.015114  [19264/60000]\n",
      "loss: 0.007643  [25664/60000]\n",
      "loss: 0.013999  [32064/60000]\n",
      "loss: 0.041806  [38464/60000]\n",
      "loss: 0.030558  [44864/60000]\n",
      "loss: 0.105405  [51264/60000]\n",
      "loss: 0.044490  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.033298 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.022182  [   64/60000]\n",
      "loss: 0.022380  [ 6464/60000]\n",
      "loss: 0.017514  [12864/60000]\n",
      "loss: 0.032104  [19264/60000]\n",
      "loss: 0.017716  [25664/60000]\n",
      "loss: 0.099899  [32064/60000]\n",
      "loss: 0.035292  [38464/60000]\n",
      "loss: 0.054067  [44864/60000]\n",
      "loss: 0.116752  [51264/60000]\n",
      "loss: 0.033681  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.042339 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.004585  [   64/60000]\n",
      "loss: 0.003510  [ 6464/60000]\n",
      "loss: 0.112595  [12864/60000]\n",
      "loss: 0.013572  [19264/60000]\n",
      "loss: 0.012716  [25664/60000]\n",
      "loss: 0.006360  [32064/60000]\n",
      "loss: 0.037084  [38464/60000]\n",
      "loss: 0.024426  [44864/60000]\n",
      "loss: 0.030024  [51264/60000]\n",
      "loss: 0.008204  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.042678 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.005311  [   64/60000]\n",
      "loss: 0.012579  [ 6464/60000]\n",
      "loss: 0.004586  [12864/60000]\n",
      "loss: 0.032787  [19264/60000]\n",
      "loss: 0.006511  [25664/60000]\n",
      "loss: 0.011799  [32064/60000]\n",
      "loss: 0.021095  [38464/60000]\n",
      "loss: 0.004981  [44864/60000]\n",
      "loss: 0.093490  [51264/60000]\n",
      "loss: 0.015686  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.039901 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.005493  [   64/60000]\n",
      "loss: 0.007533  [ 6464/60000]\n",
      "loss: 0.008893  [12864/60000]\n",
      "loss: 0.045817  [19264/60000]\n",
      "loss: 0.003393  [25664/60000]\n",
      "loss: 0.007132  [32064/60000]\n",
      "loss: 0.003537  [38464/60000]\n",
      "loss: 0.003612  [44864/60000]\n",
      "loss: 0.060841  [51264/60000]\n",
      "loss: 0.026867  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.034422 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.000513  [   64/60000]\n",
      "loss: 0.001538  [ 6464/60000]\n",
      "loss: 0.075432  [12864/60000]\n",
      "loss: 0.005326  [19264/60000]\n",
      "loss: 0.013728  [25664/60000]\n",
      "loss: 0.037700  [32064/60000]\n",
      "loss: 0.006134  [38464/60000]\n",
      "loss: 0.002209  [44864/60000]\n",
      "loss: 0.010532  [51264/60000]\n",
      "loss: 0.009350  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.044937 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.003413  [   64/60000]\n",
      "loss: 0.000661  [ 6464/60000]\n",
      "loss: 0.003888  [12864/60000]\n",
      "loss: 0.178841  [19264/60000]\n",
      "loss: 0.000996  [25664/60000]\n",
      "loss: 0.040426  [32064/60000]\n",
      "loss: 0.010821  [38464/60000]\n",
      "loss: 0.008833  [44864/60000]\n",
      "loss: 0.019370  [51264/60000]\n",
      "loss: 0.022479  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.032452 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.005943  [   64/60000]\n",
      "loss: 0.057780  [ 6464/60000]\n",
      "loss: 0.028028  [12864/60000]\n",
      "loss: 0.000173  [19264/60000]\n",
      "loss: 0.020602  [25664/60000]\n",
      "loss: 0.008355  [32064/60000]\n",
      "loss: 0.000226  [38464/60000]\n",
      "loss: 0.002228  [44864/60000]\n",
      "loss: 0.028031  [51264/60000]\n",
      "loss: 0.015925  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.040817 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    history['epoch'].append(t+1)\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimiser, history)\n",
    "    test_loop(test_dataloader, model, loss_fn, history)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [item for item in history['epoch']]\n",
    "test_losses = [item.item() for item in history['test_loss']]\n",
    "val_losses = [item for item in history['val_loss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (9,) and (10,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrain Loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs[\u001b[38;5;241m1\u001b[39m:], val_losses, color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "File \u001b[0;32m~/Documents/Data_Science_Projects/mnist_classification_pytorch/mnist_practice_venv/lib/python3.12/site-packages/matplotlib/pyplot.py:3829\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3821\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3828\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3833\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Data_Science_Projects/mnist_classification_pytorch/mnist_practice_venv/lib/python3.12/site-packages/matplotlib/axes/_axes.py:1777\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1777\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/Documents/Data_Science_Projects/mnist_classification_pytorch/mnist_practice_venv/lib/python3.12/site-packages/matplotlib/axes/_base.py:297\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Data_Science_Projects/mnist_classification_pytorch/mnist_practice_venv/lib/python3.12/site-packages/matplotlib/axes/_base.py:494\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    491\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (9,) and (10,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(epochs[1:], test_losses, color = 'blue', label = \"Train Loss\")\n",
    "plt.plot(epochs[1:], val_losses, color = 'red', label = \"Test Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist_practice_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
